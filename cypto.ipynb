{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOF29nnG9H+WnY1Mc0mtPsW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deltan2002/RNN/blob/main/cypto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4XpZh7cILoJ9",
        "outputId": "a5f9306a-52d0-4b0c-cdb0-bf24b118308b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  crypto_data.zip\n",
            "replace crypto_data/BCH-USD.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "!unzip crypto_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import preprocessing\n",
        "from collections import deque\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,LSTM,BatchNormalization\n",
        "from tensorflow.compat.v1.keras.layers import CuDNNLSTM\n",
        "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
        "\n",
        "\n",
        "# df = pd.read_csv('crypto_data/LTC-USD.csv',names=['time','low','high','open','close','volume'])\n",
        "# print(df.head())\n",
        "\n",
        "SEQ_LEN=60\n",
        "FUTURE_PERIOD_PREDICT=3\n",
        "RATIO_TO_PREDICT='LTC-USD'\n",
        "EPOCHS=2\n",
        "BATCH_SIZE=64\n",
        "NAME=f'{RATIO_TO_PREDICT}-{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}'\n",
        "\n",
        "\n",
        "\n",
        "def classify(current,future):\n",
        "  if float(future) > float(current):\n",
        "    return 1\n",
        "  else:\n",
        "    return 0\n",
        "\n",
        "\n",
        "main_df = pd.DataFrame()\n",
        "ratios = ['BTC-USD','LTC-USD','ETH-USD','BCH-USD']\n"
      ],
      "metadata": {
        "id": "9fH_A6ZNMbkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_df(df):\n",
        "  df.drop(['future'], axis=1, inplace=True)\n",
        "\n",
        "  for col in df.columns:\n",
        "    if col!='target':\n",
        "      df[col] = df[col].pct_change()\n",
        "      df.dropna(inplace=True)\n",
        "      df[col] = preprocessing.scale(df[col].values) # data b/w 0 ad 1\n",
        "\n",
        "  df.dropna(inplace=True)\n",
        "\n",
        "  sequential_data=[]\n",
        "  prev_days = deque(maxlen=SEQ_LEN)\n",
        "\n",
        "  if df is not None:\n",
        "    for i in df.values:\n",
        "      prev_days.append([n for n in i[:-1]])\n",
        "      if len(prev_days) == SEQ_LEN:\n",
        "        sequential_data.append([np.array(prev_days), i[-1]])\n",
        "  random.shuffle(sequential_data)\n",
        "\n",
        "\n",
        "  buys=[]\n",
        "  sells=[]\n",
        "\n",
        "  for seq,target in sequential_data:\n",
        "    if target ==0:\n",
        "      sells.append([seq,target])\n",
        "    else:\n",
        "      buys.append([seq,target])\n",
        "\n",
        "  random.shuffle(buys)\n",
        "  random.shuffle(sells)\n",
        "\n",
        "  lower =  min(len(buys),len(sells))\n",
        "\n",
        "  buys = buys[:lower]\n",
        "  sells = sells[:lower]\n",
        "\n",
        "\n",
        "  sequential_data = buys+sells\n",
        "  random.shuffle(sequential_data)\n",
        "\n",
        "\n",
        "  X =[]\n",
        "  y = []\n",
        "\n",
        "  for seq,target in sequential_data:\n",
        "    X.append(seq)\n",
        "    y.append(target)\n",
        "  return np.array(X),y\n",
        "\n"
      ],
      "metadata": {
        "id": "1YiGhRkMZu4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ratio in ratios:\n",
        "  dataset = f'crypto_data/{ratio}.csv'\n",
        "\n",
        "  df = pd.read_csv(dataset,names=['time','low','high','open','close','volume'])\n",
        "  df.rename(columns={'close':f'{ratio}_close','volume': f'{ratio}_volume'},inplace=True)\n",
        "\n",
        "  df.set_index('time',inplace=True)\n",
        "  df = df[[f'{ratio}_close',f'{ratio}_volume']]\n",
        "  # print(df.head())\n",
        "\n",
        "\n",
        "\n",
        "  if len(main_df) ==0:\n",
        "    main_df =df\n",
        "  else:\n",
        "    main_df = main_df.join(df,how='outer' ,rsuffix=f'_{ratio}')\n",
        "\n",
        "\n",
        "main_df['future'] = main_df[f'{RATIO_TO_PREDICT}_close'].shift(-FUTURE_PERIOD_PREDICT)\n",
        "main_df['target'] = list(map(classify, main_df[f'{RATIO_TO_PREDICT}_close'], main_df['future']))\n",
        "\n",
        "\n",
        "main_df.fillna(method=\"ffill\", inplace=True)\n",
        "main_df.dropna(inplace=True)\n",
        "\n",
        "\n",
        "\n",
        "print(main_df[[f'{RATIO_TO_PREDICT}_close','future','target']].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvwFNGTyOO6W",
        "outputId": "875f257e-dd5b-4e46-deb1-bb6c91124b43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "            LTC-USD_close     future  target\n",
            "time                                        \n",
            "1528968720      96.660004  96.389999       0\n",
            "1528968780      96.570000  96.519997       0\n",
            "1528968840      96.500000  96.440002       0\n",
            "1528968900      96.389999  96.470001       1\n",
            "1528968960      96.519997  96.400002       0\n",
            "1528969020      96.440002  96.400002       0\n",
            "1528969080      96.470001  96.400002       0\n",
            "1528969140      96.400002  96.400002       0\n",
            "1528969200      96.400002  96.400002       0\n",
            "1528969260      96.400002  96.449997       1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "times = sorted(main_df.index.values)\n",
        "last_5pct = times[-int(0.05*len(times))]\n",
        "\n",
        "validation_main_df = main_df[(main_df.index >= last_5pct)]\n",
        "main_df = main_df[(main_df.index < last_5pct)]\n",
        "\n"
      ],
      "metadata": {
        "id": "0MhHWNWVRCzM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_x,train_y = preprocess_df(main_df)\n",
        "validation_x,validation_y = preprocess_df(validation_main_df)\n",
        "\n",
        "\n",
        "train_x = np.asarray(train_x)\n",
        "train_y = np.asarray(train_y)\n",
        "validation_x = np.asarray(validation_x)\n",
        "validation_y = np.asarray(validation_y)"
      ],
      "metadata": {
        "id": "LZw_1lJrZVAA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Train Data: {len(train_x)} Validation: {len(validation_x)}')\n",
        "print(f'Dont Buys: {np.sum(train_y == 0)}, Buys: {np.sum(train_y == 1)}')\n",
        "print(f'VALIDATION Dont Buys: {np.sum(validation_y == 0)}, Buys: {np.sum(validation_y == 1)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6DMQFYq7iM2J",
        "outputId": "9bf96108-f629-4ad3-dd16-57707c71279f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Data: 80770 Validation: 3848\n",
            "Dont Buys: 40385, Buys: 40385\n",
            "VALIDATION Dont Buys: 1924, Buys: 1924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.src.optimizers import optimizer\n",
        "model = Sequential()\n",
        "model.add(LSTM(128,input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(LSTM(128,input_shape=(train_x.shape[1:]), return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(LSTM(128,input_shape=(train_x.shape[1:])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.9)\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tensorboard = TensorBoard(log_dir=f'logs/{NAME}')\n",
        "filepath = 'RNN_Final-{epoch:02d}-{val_accuracy:.3f}'\n",
        "checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'))\n",
        "\n",
        "history = model.fit(\n",
        "    train_x, train_y,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=(validation_x, validation_y),\n",
        "    callbacks=[tensorboard, checkpoint],\n",
        ")\n",
        "\n",
        "# Score model\n",
        "score = model.evaluate(validation_x, validation_y, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "# Save model\n",
        "# model.save(\"models/{}\".format(NAME))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOPpvIIJ6mFN",
        "outputId": "171409b6-e9a9-494d-97cb-8472d61cd0f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n",
            "1263/1263 [==============================] - 345s 269ms/step - loss: 0.6966 - accuracy: 0.5017 - val_loss: 0.6932 - val_accuracy: 0.5003\n",
            "Epoch 2/2\n",
            "1263/1263 [==============================] - 343s 271ms/step - loss: 0.6936 - accuracy: 0.5035 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
            "Test loss: 0.6931525468826294\n",
            "Test accuracy: 0.5\n"
          ]
        }
      ]
    }
  ]
}